# -*- coding: utf-8 -*-
# @Time    : 2023/1/16 21:20
# @Author  : 银尘
# @FileName: test_trained_model.py
# @Software: PyCharm
# @Email   : liwudi@liwudi.fun
# @Info    : 测试训练好的模型

import argparse
import ast
from collections import OrderedDict
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from PaperCrawlerUtil.common_util import *
from PaperCrawlerUtil.constant import *
from PaperCrawlerUtil.crawler_util import *
from dgl.nn import GATConv
from dtaidistance import dtw
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_validate
from torch.utils.data import DataLoader
from torch.utils.data import TensorDataset
from torch.utils.tensorboard import SummaryWriter
from model import *
from funcs import *
from params import *
from utils import *
from PaperCrawlerUtil.research_util import *

basic_config(logs_style=LOG_STYLE_ALL)
args = params()
os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu)
gpu_available = torch.cuda.is_available()
if gpu_available:
    device = torch.device('cuda:0')
else:
    device = torch.device('cpu')
dataname = args.dataname
tcity = args.tcity
datatype = args.datatype
target_data = np.load("../data/%s/%s%s_%s.npy" % (tcity, dataname, tcity, datatype))
lng_target, lat_target = target_data.shape[1], target_data.shape[2]
mask_target = target_data.sum(0) > 0
th_mask_target = torch.Tensor(mask_target.reshape(1, lng_target, lat_target)).to(device)
log("%d valid regions in target" % np.sum(mask_target))
target_emb_label = masked_percentile_label(target_data.sum(0).reshape(-1), mask_target.reshape(-1))
lag = [-6, -5, -4, -3, -2, -1]
target_data, max_val, min_val = min_max_normalize(target_data)
target_train_x, target_train_y, target_val_x, target_val_y, target_test_x, target_test_y = split_x_y(target_data, lag)
if args.data_amount != 0:
    target_train_x = target_train_x[-args.data_amount * 24:, :, :, :]
    target_train_y = target_train_y[-args.data_amount * 24:, :, :, :]
target_train_dataset = TensorDataset(torch.Tensor(target_train_x), torch.Tensor(target_train_y))
target_val_dataset = TensorDataset(torch.Tensor(target_val_x), torch.Tensor(target_val_y))
target_test_dataset = TensorDataset(torch.Tensor(target_test_x), torch.Tensor(target_test_y))
target_train_loader = DataLoader(target_train_dataset, batch_size=args.batch_size, shuffle=True)
target_val_loader = DataLoader(target_val_dataset, batch_size=args.batch_size)
target_test_loader = DataLoader(target_test_dataset, batch_size=args.batch_size)

net = STNet_nobn(1, 3, th_mask_target, sigmoid_out=True).to(device)

best_val_rmse = 999
best_test_rmse = 999
best_test_mae = 999
best_teat_mape = 999


def evaluate(net_, loader, spatial_mask):
    net_.eval()
    with torch.no_grad():
        se = 0
        ae = 0
        mape = 0
        valid_points = 0
        apes = 0
        losses = []
        for it_ in loader:
            if len(it_) == 2:
                (x, y) = it_
            elif len(it_) == 4:
                _, _, x, y = it_
            x = x.to(device)
            y = y.to(device)
            lng = x.shape[2]
            lat = x.shape[3]
            out = net_(x, spatial_mask=spatial_mask.bool())
            valid_points += x.shape[0] * spatial_mask.sum().item()
            apes += (y > 1e-6).sum().item()
            if len(out.shape) == 4: 
                se += (((out - y) ** 2) * (spatial_mask.view(1, 1, lng, lat))).sum().item()
                ae += ((out - y).abs() * (spatial_mask.view(1, 1, lng, lat))).sum().item()
                eff_batch_size = y.shape[0]
                loss = ((out - y) ** 2).view(eff_batch_size, 1, -1)[:, :, spatial_mask.view(-1).bool()]
                losses.append(loss)
                with np.errstate(divide='ignore', invalid='ignore'):
                    ape = (out - y).abs() / y
                    ape = ape.cpu().numpy().flatten()
                    ape[~ np.isfinite(ape)] = 0 
                    mape += ape.sum().item()
            elif len(out.shape) == 3: 
                batch_size = y.shape[0]
                lag = y.shape[1]
                y = torch.where(y.abs() < 1e-6, 0, y)
                y = y.view(batch_size, lag, -1)[:, :, spatial_mask.view(-1).bool()]
                se += ((out - y) ** 2).sum().item()
                ae += (out - y).abs().sum().item()
                loss = ((out - y) ** 2)
                losses.append(loss)
                with np.errstate(divide='ignore', invalid='ignore'):
                    ape = (out - y).abs() / y
                    ape = ape.cpu().numpy().flatten()
                    ape[~ np.isfinite(ape)] = 0
                    mape += ape.sum().item()
    return np.sqrt(se / valid_points), ae / valid_points, losses, mape / apes


p_bar = process_bar(final_prompt="测试完成", unit="epoch")
p_bar.process(0, 1, 1)
net = torch.load(args.test_mode_path)
for ep in range(1):

    net.eval()
    rmse_val, mae_val, val_losses, mape_val = evaluate(net, target_val_loader, spatial_mask=th_mask_target)
    rmse_test, mae_test, test_losses, mape_test = evaluate(net, target_test_loader, spatial_mask=th_mask_target)
    if rmse_val < best_val_rmse:
        best_val_rmse = rmse_val
        best_test_rmse = rmse_test
        best_test_mae = mae_test
        best_teat_mape = mape_test
        log("Update best test...")

    log()
    p_bar.process(0, 1, 1)

log("Best test rmse %.4f, mae %.4f, mape %.4f" % (
best_test_rmse * (max_val - min_val), best_test_mae * (max_val - min_val), best_teat_mape * 100))
write_file("./test_result.res", mode="a+", string="{} {} {}: ".
           format(dataname, datatype, str(args.data_amount)) + "%.4f, %.4f, %.4f \n" % (
                                                  best_test_rmse * (max_val - min_val),
                                                  best_test_mae * (max_val - min_val),
                                                  best_teat_mape * 100))
